{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2dbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78801139",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='''The wind whispered through the tall trees.\n",
    "The sun dipped behind the hills, casting long shadows across the quiet valley.\n",
    "Birds fluttered above, their wings slicing the cool evening air.\n",
    "A gentle stream trickled nearby, humming its ancient song.\n",
    "A boy stood alone on the worn trail.\n",
    "He stared ahead with both curiosity and hesitation.\n",
    "His backpack was light, yet his heart felt heavy with the unknown.\n",
    "Every step forward felt like a choice.\n",
    "It was a silent commitment to change.\n",
    "The world around him seemed alive, listening, waiting.\n",
    "Though he didn’t know what lay ahead, he chose to move.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b869956",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec6a550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'a': 2,\n",
       " 'he': 3,\n",
       " 'ahead': 4,\n",
       " 'with': 5,\n",
       " 'his': 6,\n",
       " 'was': 7,\n",
       " 'felt': 8,\n",
       " 'to': 9,\n",
       " 'wind': 10,\n",
       " 'whispered': 11,\n",
       " 'through': 12,\n",
       " 'tall': 13,\n",
       " 'trees': 14,\n",
       " 'sun': 15,\n",
       " 'dipped': 16,\n",
       " 'behind': 17,\n",
       " 'hills': 18,\n",
       " 'casting': 19,\n",
       " 'long': 20,\n",
       " 'shadows': 21,\n",
       " 'across': 22,\n",
       " 'quiet': 23,\n",
       " 'valley': 24,\n",
       " 'birds': 25,\n",
       " 'fluttered': 26,\n",
       " 'above': 27,\n",
       " 'their': 28,\n",
       " 'wings': 29,\n",
       " 'slicing': 30,\n",
       " 'cool': 31,\n",
       " 'evening': 32,\n",
       " 'air': 33,\n",
       " 'gentle': 34,\n",
       " 'stream': 35,\n",
       " 'trickled': 36,\n",
       " 'nearby': 37,\n",
       " 'humming': 38,\n",
       " 'its': 39,\n",
       " 'ancient': 40,\n",
       " 'song': 41,\n",
       " 'boy': 42,\n",
       " 'stood': 43,\n",
       " 'alone': 44,\n",
       " 'on': 45,\n",
       " 'worn': 46,\n",
       " 'trail': 47,\n",
       " 'stared': 48,\n",
       " 'both': 49,\n",
       " 'curiosity': 50,\n",
       " 'and': 51,\n",
       " 'hesitation': 52,\n",
       " 'backpack': 53,\n",
       " 'light': 54,\n",
       " 'yet': 55,\n",
       " 'heart': 56,\n",
       " 'heavy': 57,\n",
       " 'unknown': 58,\n",
       " 'every': 59,\n",
       " 'step': 60,\n",
       " 'forward': 61,\n",
       " 'like': 62,\n",
       " 'choice': 63,\n",
       " 'it': 64,\n",
       " 'silent': 65,\n",
       " 'commitment': 66,\n",
       " 'change': 67,\n",
       " 'world': 68,\n",
       " 'around': 69,\n",
       " 'him': 70,\n",
       " 'seemed': 71,\n",
       " 'alive': 72,\n",
       " 'listening': 73,\n",
       " 'waiting': 74,\n",
       " 'though': 75,\n",
       " 'didn’t': 76,\n",
       " 'know': 77,\n",
       " 'what': 78,\n",
       " 'lay': 79,\n",
       " 'chose': 80,\n",
       " 'move': 81}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68687096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind whispered through the tall trees.\n",
      "The sun dipped behind the hills, casting long shadows across the quiet valley.\n",
      "Birds fluttered above, their wings slicing the cool evening air.\n",
      "A gentle stream trickled nearby, humming its ancient song.\n",
      "A boy stood alone on the worn trail.\n",
      "He stared ahead with both curiosity and hesitation.\n",
      "His backpack was light, yet his heart felt heavy with the unknown.\n",
      "Every step forward felt like a choice.\n",
      "It was a silent commitment to change.\n",
      "The world around him seemed alive, listening, waiting.\n",
      "Though he didn’t know what lay ahead, he chose to move.\n"
     ]
    }
   ],
   "source": [
    "for sentences in sentence.split('\\n'):\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151e520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 11, 12, 1, 13, 14]\n",
      "[1, 15, 16, 17, 1, 18, 19, 20, 21, 22, 1, 23, 24]\n",
      "[25, 26, 27, 28, 29, 30, 1, 31, 32, 33]\n",
      "[2, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "[2, 42, 43, 44, 45, 1, 46, 47]\n",
      "[3, 48, 4, 5, 49, 50, 51, 52]\n",
      "[6, 53, 7, 54, 55, 6, 56, 8, 57, 5, 1, 58]\n",
      "[59, 60, 61, 8, 62, 2, 63]\n",
      "[64, 7, 2, 65, 66, 9, 67]\n",
      "[1, 68, 69, 70, 71, 72, 73, 74]\n",
      "[75, 3, 76, 77, 78, 79, 4, 3, 80, 9, 81]\n"
     ]
    }
   ],
   "source": [
    "for sentences in sentence.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentences])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300cde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentences in sentence.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentences])[0]\n",
    "\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "       input_sequences.append(tokenized_sentence[:i+1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15cc449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 10], [1, 10, 11], [1, 10, 11, 12], [1, 10, 11, 12, 1], [1, 10, 11, 12, 1, 13], [1, 10, 11, 12, 1, 13, 14], [1, 15], [1, 15, 16], [1, 15, 16, 17], [1, 15, 16, 17, 1], [1, 15, 16, 17, 1, 18], [1, 15, 16, 17, 1, 18, 19], [1, 15, 16, 17, 1, 18, 19, 20], [1, 15, 16, 17, 1, 18, 19, 20, 21], [1, 15, 16, 17, 1, 18, 19, 20, 21, 22], [1, 15, 16, 17, 1, 18, 19, 20, 21, 22, 1], [1, 15, 16, 17, 1, 18, 19, 20, 21, 22, 1, 23], [1, 15, 16, 17, 1, 18, 19, 20, 21, 22, 1, 23, 24], [25, 26], [25, 26, 27], [25, 26, 27, 28], [25, 26, 27, 28, 29], [25, 26, 27, 28, 29, 30], [25, 26, 27, 28, 29, 30, 1], [25, 26, 27, 28, 29, 30, 1, 31], [25, 26, 27, 28, 29, 30, 1, 31, 32], [25, 26, 27, 28, 29, 30, 1, 31, 32, 33], [2, 34], [2, 34, 35], [2, 34, 35, 36], [2, 34, 35, 36, 37], [2, 34, 35, 36, 37, 38], [2, 34, 35, 36, 37, 38, 39], [2, 34, 35, 36, 37, 38, 39, 40], [2, 34, 35, 36, 37, 38, 39, 40, 41], [2, 42], [2, 42, 43], [2, 42, 43, 44], [2, 42, 43, 44, 45], [2, 42, 43, 44, 45, 1], [2, 42, 43, 44, 45, 1, 46], [2, 42, 43, 44, 45, 1, 46, 47], [3, 48], [3, 48, 4], [3, 48, 4, 5], [3, 48, 4, 5, 49], [3, 48, 4, 5, 49, 50], [3, 48, 4, 5, 49, 50, 51], [3, 48, 4, 5, 49, 50, 51, 52], [6, 53], [6, 53, 7], [6, 53, 7, 54], [6, 53, 7, 54, 55], [6, 53, 7, 54, 55, 6], [6, 53, 7, 54, 55, 6, 56], [6, 53, 7, 54, 55, 6, 56, 8], [6, 53, 7, 54, 55, 6, 56, 8, 57], [6, 53, 7, 54, 55, 6, 56, 8, 57, 5], [6, 53, 7, 54, 55, 6, 56, 8, 57, 5, 1], [6, 53, 7, 54, 55, 6, 56, 8, 57, 5, 1, 58], [59, 60], [59, 60, 61], [59, 60, 61, 8], [59, 60, 61, 8, 62], [59, 60, 61, 8, 62, 2], [59, 60, 61, 8, 62, 2, 63], [64, 7], [64, 7, 2], [64, 7, 2, 65], [64, 7, 2, 65, 66], [64, 7, 2, 65, 66, 9], [64, 7, 2, 65, 66, 9, 67], [1, 68], [1, 68, 69], [1, 68, 69, 70], [1, 68, 69, 70, 71], [1, 68, 69, 70, 71, 72], [1, 68, 69, 70, 71, 72, 73], [1, 68, 69, 70, 71, 72, 73, 74], [75, 3], [75, 3, 76], [75, 3, 76, 77], [75, 3, 76, 77, 78], [75, 3, 76, 77, 78, 79], [75, 3, 76, 77, 78, 79, 4], [75, 3, 76, 77, 78, 79, 4, 3], [75, 3, 76, 77, 78, 79, 4, 3, 80], [75, 3, 76, 77, 78, 79, 4, 3, 80, 9], [75, 3, 76, 77, 78, 79, 4, 3, 80, 9, 81]]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdac296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "max_len1 = max([len(x) for x in input_sequences])\n",
    "print(max_len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678ce4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen =max_len1, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a09fdef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  1, 10],\n",
       "       [ 0,  0,  0, ...,  1, 10, 11],\n",
       "       [ 0,  0,  0, ..., 10, 11, 12],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  4,  3, 80],\n",
       "       [ 0,  0,  0, ...,  3, 80,  9],\n",
       "       [ 0,  0, 75, ..., 80,  9, 81]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6668fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  1],\n",
       "       [ 0,  0,  0, ...,  0,  1, 10],\n",
       "       [ 0,  0,  0, ...,  1, 10, 11],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 79,  4,  3],\n",
       "       [ 0,  0,  0, ...,  4,  3, 80],\n",
       "       [ 0,  0, 75, ...,  3, 80,  9]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=padded_input_sequences[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a87f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12,  1, 13, 14, 15, 16, 17,  1, 18, 19, 20, 21, 22,  1, 23,\n",
       "       24, 26, 27, 28, 29, 30,  1, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
       "       41, 42, 43, 44, 45,  1, 46, 47, 48,  4,  5, 49, 50, 51, 52, 53,  7,\n",
       "       54, 55,  6, 56,  8, 57,  5,  1, 58, 60, 61,  8, 62,  2, 63,  7,  2,\n",
       "       65, 66,  9, 67, 68, 69, 70, 71, 72, 73, 74,  3, 76, 77, 78, 79,  4,\n",
       "        3, 80,  9, 81], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=padded_input_sequences[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f8a38d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b47d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb17906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y= to_categorical(y,num_classes=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98554953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c9b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a49a637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\python workspace\\allvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Embedding(82,100,input_length=13))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(82,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b0e56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,382</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m8,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)             │        \u001b[38;5;34m12,382\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171,182</span> (668.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m171,182\u001b[0m (668.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171,182</span> (668.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m171,182\u001b[0m (668.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 13))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c7a73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0615 - loss: 4.4080\n",
      "Epoch 2/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0845 - loss: 4.3961\n",
      "Epoch 3/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0571 - loss: 4.3850\n",
      "Epoch 4/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0611 - loss: 4.3720\n",
      "Epoch 5/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0689 - loss: 4.3530\n",
      "Epoch 6/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0611 - loss: 4.3206\n",
      "Epoch 7/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0806 - loss: 4.2555\n",
      "Epoch 8/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0571 - loss: 4.2329\n",
      "Epoch 9/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0728 - loss: 4.2339\n",
      "Epoch 10/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0532 - loss: 4.1931\n",
      "Epoch 11/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0571 - loss: 4.1417\n",
      "Epoch 12/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0650 - loss: 4.1024\n",
      "Epoch 13/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0706 - loss: 3.9961\n",
      "Epoch 14/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0879 - loss: 3.9297\n",
      "Epoch 15/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0974 - loss: 3.8741\n",
      "Epoch 16/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0857 - loss: 3.7518\n",
      "Epoch 17/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0801 - loss: 3.6765\n",
      "Epoch 18/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0606 - loss: 3.6053\n",
      "Epoch 19/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1187 - loss: 3.4465\n",
      "Epoch 20/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1221 - loss: 3.4037\n",
      "Epoch 21/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1048 - loss: 3.2784\n",
      "Epoch 22/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1590 - loss: 3.1334\n",
      "Epoch 23/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1641 - loss: 3.0436\n",
      "Epoch 24/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2335 - loss: 2.9190\n",
      "Epoch 25/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2486 - loss: 2.8543\n",
      "Epoch 26/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2659 - loss: 2.7948\n",
      "Epoch 27/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3001 - loss: 2.6988\n",
      "Epoch 28/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2953 - loss: 2.5679\n",
      "Epoch 29/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4181 - loss: 2.4104\n",
      "Epoch 30/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4015 - loss: 2.3531\n",
      "Epoch 31/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4396 - loss: 2.2640\n",
      "Epoch 32/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4759 - loss: 2.1932\n",
      "Epoch 33/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5704 - loss: 2.1582\n",
      "Epoch 34/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5448 - loss: 2.0403\n",
      "Epoch 35/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5783 - loss: 1.9178\n",
      "Epoch 36/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6606 - loss: 1.8891\n",
      "Epoch 37/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6769 - loss: 1.8429\n",
      "Epoch 38/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7094 - loss: 1.8397\n",
      "Epoch 39/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5690 - loss: 1.7529\n",
      "Epoch 40/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7433 - loss: 1.6677\n",
      "Epoch 41/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6361 - loss: 1.6971\n",
      "Epoch 42/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7402 - loss: 1.5685\n",
      "Epoch 43/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7172 - loss: 1.5303\n",
      "Epoch 44/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 1.5520\n",
      "Epoch 45/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7206 - loss: 1.4759\n",
      "Epoch 46/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8046 - loss: 1.3661\n",
      "Epoch 47/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 1.3565\n",
      "Epoch 48/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7795 - loss: 1.3645\n",
      "Epoch 49/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8242 - loss: 1.3400\n",
      "Epoch 50/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7717 - loss: 1.2871\n",
      "Epoch 51/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8471 - loss: 1.2104\n",
      "Epoch 52/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 1.1924\n",
      "Epoch 53/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8081 - loss: 1.1743\n",
      "Epoch 54/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8003 - loss: 1.1503\n",
      "Epoch 55/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8718 - loss: 1.1253\n",
      "Epoch 56/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8701 - loss: 1.0443\n",
      "Epoch 57/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8930 - loss: 1.0400\n",
      "Epoch 58/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9121 - loss: 1.0192\n",
      "Epoch 59/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8948 - loss: 0.9905\n",
      "Epoch 60/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9333 - loss: 0.9234\n",
      "Epoch 61/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9255 - loss: 0.9580\n",
      "Epoch 62/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9121 - loss: 0.8567\n",
      "Epoch 63/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9424 - loss: 0.9372\n",
      "Epoch 64/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9407 - loss: 0.9088\n",
      "Epoch 65/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9446 - loss: 0.8740\n",
      "Epoch 66/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9389 - loss: 0.8499\n",
      "Epoch 67/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9446 - loss: 0.7639\n",
      "Epoch 68/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.8063\n",
      "Epoch 69/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9563 - loss: 0.7350\n",
      "Epoch 70/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.6940\n",
      "Epoch 71/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9446 - loss: 0.7330\n",
      "Epoch 72/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9641 - loss: 0.6602\n",
      "Epoch 73/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.7611\n",
      "Epoch 74/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9463 - loss: 0.7258\n",
      "Epoch 75/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9697 - loss: 0.6814\n",
      "Epoch 76/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.7000\n",
      "Epoch 77/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9389 - loss: 0.6395\n",
      "Epoch 78/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9580 - loss: 0.6563\n",
      "Epoch 79/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9580 - loss: 0.6071\n",
      "Epoch 80/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9541 - loss: 0.6158\n",
      "Epoch 81/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9385 - loss: 0.6063\n",
      "Epoch 82/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9658 - loss: 0.5419\n",
      "Epoch 83/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9541 - loss: 0.5557\n",
      "Epoch 84/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.5353\n",
      "Epoch 85/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9580 - loss: 0.5501\n",
      "Epoch 86/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9619 - loss: 0.5207\n",
      "Epoch 87/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9524 - loss: 0.5502\n",
      "Epoch 88/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9541 - loss: 0.4963\n",
      "Epoch 89/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9541 - loss: 0.4886\n",
      "Epoch 90/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9636 - loss: 0.5014\n",
      "Epoch 91/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9558 - loss: 0.5186\n",
      "Epoch 92/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9502 - loss: 0.4673\n",
      "Epoch 93/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.4767\n",
      "Epoch 94/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.4172\n",
      "Epoch 95/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9792 - loss: 0.4320\n",
      "Epoch 96/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.4063\n",
      "Epoch 97/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9558 - loss: 0.4129\n",
      "Epoch 98/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 0.3860\n",
      "Epoch 99/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9558 - loss: 0.4133\n",
      "Epoch 100/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9831 - loss: 0.3675\n",
      "Epoch 101/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9675 - loss: 0.3824\n",
      "Epoch 102/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.3843\n",
      "Epoch 103/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9446 - loss: 0.3717\n",
      "Epoch 104/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.3722\n",
      "Epoch 105/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9675 - loss: 0.3528\n",
      "Epoch 106/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.3634\n",
      "Epoch 107/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.3344\n",
      "Epoch 108/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.3254\n",
      "Epoch 109/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9580 - loss: 0.3329\n",
      "Epoch 110/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.3314\n",
      "Epoch 111/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9675 - loss: 0.3203\n",
      "Epoch 112/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9558 - loss: 0.3311\n",
      "Epoch 113/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.3027\n",
      "Epoch 114/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9558 - loss: 0.2918\n",
      "Epoch 115/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9597 - loss: 0.2955\n",
      "Epoch 116/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9792 - loss: 0.3065\n",
      "Epoch 117/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.2750\n",
      "Epoch 118/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9675 - loss: 0.2853\n",
      "Epoch 119/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9597 - loss: 0.2946\n",
      "Epoch 120/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.2695\n",
      "Epoch 121/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9675 - loss: 0.2705\n",
      "Epoch 122/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.2814\n",
      "Epoch 123/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.2552\n",
      "Epoch 124/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.2548\n",
      "Epoch 125/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9831 - loss: 0.2556\n",
      "Epoch 126/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9792 - loss: 0.2281\n",
      "Epoch 127/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9636 - loss: 0.2647\n",
      "Epoch 128/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9619 - loss: 0.2424\n",
      "Epoch 129/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.2373\n",
      "Epoch 130/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 0.2305\n",
      "Epoch 131/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9558 - loss: 0.2469\n",
      "Epoch 132/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9675 - loss: 0.2312\n",
      "Epoch 133/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9597 - loss: 0.2314\n",
      "Epoch 134/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9480 - loss: 0.2335\n",
      "Epoch 135/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.2195\n",
      "Epoch 136/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9580 - loss: 0.2140\n",
      "Epoch 137/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.1983\n",
      "Epoch 138/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.2152\n",
      "Epoch 139/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9558 - loss: 0.2107\n",
      "Epoch 140/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.2146\n",
      "Epoch 141/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9831 - loss: 0.1838\n",
      "Epoch 142/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9446 - loss: 0.2052\n",
      "Epoch 143/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.1843\n",
      "Epoch 144/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9675 - loss: 0.2021\n",
      "Epoch 145/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9697 - loss: 0.1921\n",
      "Epoch 146/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.1655\n",
      "Epoch 147/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.1734\n",
      "Epoch 148/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9502 - loss: 0.1941\n",
      "Epoch 149/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9385 - loss: 0.1962\n",
      "Epoch 150/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.1575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22e37e02d90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608b43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "It was\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "It was a\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "It was a silent\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "It was a silent commitment\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "It was a silent commitment commitment\n"
     ]
    }
   ],
   "source": [
    "#predicting the next word\n",
    "import time\n",
    "import numpy as np\n",
    "text= \"It\"\n",
    "for i in range(5):\n",
    "    #tokenize\n",
    "    token_text= tokenizer.texts_to_sequences([text])[0]\n",
    "    #padding\n",
    "    padded_token_text= pad_sequences([token_text],maxlen=13, padding='pre')\n",
    "    #predict\n",
    "    pos= np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "            text = text + \" \" + word\n",
    "            print(text)\n",
    "            time.sleep(2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
